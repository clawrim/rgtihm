{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd7d339f-921a-40d7-9dad-1795180055e5",
   "metadata": {},
   "source": [
    "## libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b8b4e26-54a4-41c8-9392-2d41ee8e2660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.9 (main, Apr  2 2024, 13:43:44) [GCC 13.2.0]\n",
      "numpy version: 1.26.3\n",
      "matplotlib version: 3.9.2\n",
      "flopy version: 3.9.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from pprint import pformat\n",
    "from tempfile import TemporaryDirectory\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pooch\n",
    "import flopy\n",
    "import flopy.plot\n",
    "import flopy.utils\n",
    "import rasterio\n",
    "from rasterio.features import rasterize\n",
    "from shapely.geometry import box\n",
    "import contextily as cx\n",
    "print(sys.version)\n",
    "print(f\"numpy version: {np.__version__}\")\n",
    "print(f\"matplotlib version: {mpl.__version__}\")\n",
    "print(f\"flopy version: {flopy.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3850da17-34aa-4f66-a4fc-c9e0881a623e",
   "metadata": {},
   "source": [
    "## define simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89c48397-f802-4578-b20b-337fe58f4938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulation and gwf packages created.\n"
     ]
    }
   ],
   "source": [
    "# simulation setup\n",
    "sim_name = 'rgtihm'\n",
    "workspace = './model'\n",
    "sim = flopy.mf6.MFSimulation(\n",
    "    sim_name=sim_name,\n",
    "    sim_ws=workspace,\n",
    "    exe_name='mf6')\n",
    "gwf = flopy.mf6.ModflowGwf(sim,\n",
    "                           modelname=sim_name)\n",
    "print(\"simulation and gwf packages created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe90feef-8c1a-4768-9754-ab971b108e38",
   "metadata": {},
   "source": [
    "## tdis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28a77dbc-ce21-4a5e-9f87-277c636d4027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tdis package created.\n"
     ]
    }
   ],
   "source": [
    "# tdis (temporal discretization) parameters\n",
    "nper = 898\n",
    "start_date = datetime(1940, 3, 1)\n",
    "perioddata = []\n",
    "for i in range(nper):\n",
    "    month_start = start_date + timedelta(days=sum(p[0] for p in perioddata))\n",
    "    if month_start.month == 12:\n",
    "        month_end = datetime(month_start.year + 1, 1, 1)\n",
    "    else:\n",
    "        month_end = datetime(month_start.year, month_start.month + 1, 1)\n",
    "    perlen = (month_end - month_start).days\n",
    "    nstp = 2\n",
    "    tsmult = 1.0\n",
    "    perioddata.append((float(perlen), nstp, tsmult))\n",
    "\n",
    "# create tdis\n",
    "tdis = flopy.mf6.ModflowTdis(\n",
    "    sim,\n",
    "    time_units='days',\n",
    "    nper=nper,\n",
    "    perioddata=perioddata,\n",
    "    start_date_time=start_date.strftime('%Y-%m-%d'),\n",
    ")\n",
    "print(\"tdis package created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda27b66-96f0-402e-a962-a541b8c5c39d",
   "metadata": {},
   "source": [
    "## dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a13190e-3114-4303-9658-ae9b9230e181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "active cells: 52128/299136\n",
      "grid bounds: 251621.63, 386256.62, 3472061.77, 3666237.73\n",
      "shapefile bounds: [ 263314.4498 3490036.7519  357957.0726 3644537.2572]\n",
      "idomain active per layer: [52128, 52128, 52128, 52128, 52128, 52128, 52128, 52128, 52128]\n",
      "dis set with idomain from shapefile, all layers \n",
      "dis package created.\n"
     ]
    }
   ],
   "source": [
    "# tried feet units with meter crs, failed due to misalignment; tried rotation from lower-left, shifted grid left\n",
    "# tried fixing top-left rotation, still misaligned; adopted anchoring rotation at top-left, matching qgis points\n",
    "# our thinking: use exact qgis corners for precision, ensure grid aligns with real-world data via rasterio\n",
    "\n",
    "# model crs for spatial reference\n",
    "model_crs = 'epsg:26913'\n",
    "xul = 251539.8073999998  # top-left x in meters, matches qgis\n",
    "yul = 3639665.581800001  # top-left y in meters, matches qgis\n",
    "angrot = 24.0  # rotation in degrees, matches qgis\n",
    "\n",
    "# grid setup, all in meters\n",
    "nlay = 9  # number of layers\n",
    "nrow = 912  # number of rows\n",
    "ncol = 328  # number of columns\n",
    "delr = np.full(ncol, 660.0 * 0.3048)  # cell width in meters (660 ft to m)\n",
    "delc = np.full(nrow, 660.0 * 0.3048)  # cell height in meters (660 ft to m)\n",
    "# elevation data paths\n",
    "top_file = '../owhm/model/2022/Data_Model_Arrays/layers/ElevFtDEMR.txt'\n",
    "bot_files = [\n",
    "    '../owhm/model/2022/Data_Model_Arrays/layers/Top_RC2_ft.txt',\n",
    "    '../owhm/model/2022/Data_Model_Arrays/layers/Top_USF1_ft.txt',\n",
    "    '../owhm/model/2022/Data_Model_Arrays/layers/Top_USF2_ft.txt',\n",
    "    '../owhm/model/2022/Data_Model_Arrays/layers/Top_MSF1_ft.txt',\n",
    "    '../owhm/model/2022/Data_Model_Arrays/layers/Top_MSF2_ft.txt',\n",
    "    '../owhm/model/2022/Data_Model_Arrays/layers/TopLSF1_ft.txt',\n",
    "    '../owhm/model/2022/Data_Model_Arrays/layers/Top_LSF2_ft.txt',\n",
    "    '../owhm/model/2022/Data_Model_Arrays/layers/TopBSMT_ft.txt',\n",
    "    '../owhm/model/2022/Data_Model_Arrays/layers/BaseBSMT_ft.txt',\n",
    "]\n",
    "\n",
    "# load top elevation, convert feet to meters\n",
    "try:\n",
    "    top = np.loadtxt(top_file, dtype=float)\n",
    "    if top.shape != (nrow, ncol):\n",
    "        print(f\"warning: top shape mismatch {top.shape}\")\n",
    "        top = top.reshape(nrow, ncol)[:nrow, :ncol]\n",
    "    top = np.where(top == -99999, np.nan, top * 0.3048)  # ft to m\n",
    "except Exception as e:\n",
    "    print(f\"error: loading top - {e}. exiting.\")\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "# load bottom elevations, convert feet to meters\n",
    "botm = np.zeros((nlay, nrow, ncol), dtype=float)\n",
    "for lay, bot_file in enumerate(bot_files):\n",
    "    try:\n",
    "        data = np.loadtxt(bot_file, dtype=float)\n",
    "        if data.shape != (nrow, ncol):\n",
    "            print(f\"warning: bot shape mismatch {data.shape}\")\n",
    "            data = data.reshape(nrow, ncol)[:nrow, :ncol]\n",
    "        botm[lay] = np.where(data == -99999, np.nan, data * 0.3048)  # ft to m\n",
    "    except Exception as e:\n",
    "        print(f\"error: loading bot layer {lay} - {e}. exiting.\")\n",
    "        import sys\n",
    "        sys.exit(1)\n",
    "\n",
    "# load active area shapefile\n",
    "shp_path = './shps/active_area.shp'\n",
    "try:\n",
    "    gdf = gpd.read_file(shp_path)\n",
    "    if gdf.crs != model_crs:\n",
    "        print(f\"reprojecting shapefile crs\")\n",
    "        gdf = gdf.to_crs(model_crs)\n",
    "    if len(gdf) != 1:\n",
    "        print(f\"warning: multiple features, using first\")\n",
    "    geometry = gdf.geometry.iloc[0]\n",
    "except Exception as e:\n",
    "    print(f\"error: loading shapefile - {e}. exiting.\")\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "# set grid lower-left origin from qgis bottom-left\n",
    "xll = 326161.8336  # lower-left x, from qgis bl\n",
    "yll = 3472061.7670000014  # lower-left y, from qgis bl\n",
    "theta = np.radians(angrot)\n",
    "\n",
    "# grid coordinates, rotated to match qgis points\n",
    "x = np.arange(ncol) * delr[0]\n",
    "y = np.arange(nrow) * delc[0]\n",
    "X, Y = np.meshgrid(x, y)\n",
    "X_rot = xll + X * np.cos(theta) - Y * np.sin(theta)\n",
    "Y_rot = yll + X * np.sin(theta) + Y * np.cos(theta)\n",
    "\n",
    "# raster bounds in meters\n",
    "minx, maxx = X_rot.min(), X_rot.max()\n",
    "miny, maxy = Y_rot.min(), Y_rot.max()\n",
    "\n",
    "# rasterize active area to define idomain\n",
    "transform = rasterio.transform.from_bounds(minx, miny, maxx, maxy, ncol, nrow)\n",
    "raster = rasterize([geometry], out_shape=(nrow, ncol), transform=transform, fill=0, default_value=1, dtype='int32')\n",
    "\n",
    "# check raster coverage\n",
    "print(f\"active cells: {raster.sum()}/{nrow * ncol}\")\n",
    "print(f\"grid bounds: {minx:.2f}, {maxx:.2f}, {miny:.2f}, {maxy:.2f}\")\n",
    "print(f\"shapefile bounds: {gdf.total_bounds}\")\n",
    "if raster.sum() == 0:\n",
    "    print(\"error: no active cells - check alignment\")\n",
    "\n",
    "# create 3d idomain for all layers\n",
    "idomain = np.ones((nlay, nrow, ncol), dtype=int) * raster[np.newaxis, :, :]\n",
    "\n",
    "# verify idomain\n",
    "print(f\"idomain active per layer: {[idomain[lay].sum() for lay in range(nlay)]}\")\n",
    "\n",
    "# method: used geometric transformation with rasterio to align grid and shapefile\n",
    "# technique: anchored rotation at top-left, matched qgis points for precision\n",
    "# reason: ensures perfect alignment with real-world data, avoiding misalignment\n",
    "dis = flopy.mf6.ModflowGwfdis(\n",
    "    gwf,\n",
    "    nlay=nlay,\n",
    "    nrow=nrow,\n",
    "    ncol=ncol,\n",
    "    delr=delr,\n",
    "    delc=delc,\n",
    "    top=top,\n",
    "    botm=botm,\n",
    "    idomain=idomain,\n",
    "   # length_units=length_units,\n",
    "    xorigin=xll,\n",
    "    yorigin=yll,\n",
    "    angrot=angrot,\n",
    ")\n",
    "print(\"dis set with idomain from shapefile, all layers \\ndis package created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5086d6-e9e0-4748-9aef-0e508a4a99b3",
   "metadata": {},
   "source": [
    "## oc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d88b60f-cdb6-455a-a3cf-f76535a1e39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oc package created.\n"
     ]
    }
   ],
   "source": [
    "# create oc (output control) package\n",
    "oc = flopy.mf6.ModflowGwfoc(\n",
    "    gwf,\n",
    "    budget_filerecord=f'{sim_name}.cbc',\n",
    "    head_filerecord=f'{sim_name}.hds',\n",
    "    headprintrecord=[('COLUMNS', 10, 'WIDTH', 15, 'DIGITS', 6, 'GENERAL')],\n",
    "    saverecord=[('HEAD', 'ALL'), ('BUDGET', 'ALL')],\n",
    "    printrecord=[('HEAD', 'ALL'), ('BUDGET', 'ALL')],\n",
    ")\n",
    "print(\"oc package created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0540e5-278d-4078-a404-9cce7b2b589a",
   "metadata": {},
   "source": [
    "## ims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f935c5ae-55d6-48d5-89ab-5312ed016fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ims package created.\n"
     ]
    }
   ],
   "source": [
    "# iterative model solution (ims)\n",
    "ims = flopy.mf6.ModflowIms(\n",
    "    sim,\n",
    "    pname='ims',\n",
    "    complexity='simple',\n",
    "    outer_dvclose=1e-4,\n",
    "    outer_maximum=500,\n",
    "    inner_maximum=100,\n",
    "    inner_dvclose=1e-4,\n",
    "    rcloserecord=0.001,\n",
    "    linear_acceleration='cg',\n",
    "    relaxation_factor=0.97,\n",
    ")\n",
    "print(\"ims package created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afdfd8e-5eb2-481c-881a-303de21b7222",
   "metadata": {},
   "source": [
    "## ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44772300-95b7-4d52-b539-2d6a7e429b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN in strt fixed after interpolation: True\n",
      "Layer 0 strt (active) min/max: 1133.921532 1223.290416\n",
      "Layer 1 strt (active) min/max: 1129.3495320000002 1510.0294920000001\n",
      "Layer 2 strt (active) min/max: 1134.0480240000002 1510.079784\n",
      "Layer 3 strt (active) min/max: 1134.0480240000002 1510.079784\n",
      "Layer 4 strt (active) min/max: 1134.0480240000002 1510.079784\n",
      "Layer 5 strt (active) min/max: 1134.0480240000002 1510.079784\n",
      "Layer 6 strt (active) min/max: 1134.0480240000002 1510.079784\n",
      "Layer 7 strt (active) min/max: 1134.0480240000002 1548.356568\n",
      "Layer 8 strt (active) min/max: 1134.0480240000002 1548.356568\n",
      "WARNING: Package with type ic already exists. Replacing existing package.\n",
      "ic package created with -999 as no-data, idomain from shapefile, and interpolated active heads.\n"
     ]
    }
   ],
   "source": [
    "# grid dimensions (from dis)\n",
    "nlay = 9\n",
    "nrow = 912\n",
    "ncol = 328\n",
    "\n",
    "# head file paths (relative to rgtihm-main/model)\n",
    "head_files = [\n",
    "    '../owhm/model/2022/Data_Model_Arrays/layers/Initial_Head/WLCLY1.txt',\n",
    "    '../owhm/model/2022/Data_Model_Arrays/layers/Initial_Head/WLCLY2.txt',\n",
    "    '../owhm/model/2022/Data_Model_Arrays/layers/Initial_Head/WLCLY3.txt',\n",
    "    '../owhm/model/2022/Data_Model_Arrays/layers/Initial_Head/WLCLY4.txt',\n",
    "    '../owhm/model/2022/Data_Model_Arrays/layers/Initial_Head/WLCLY5.txt',\n",
    "    '../owhm/model/2022/Data_Model_Arrays/layers/Initial_Head/WLCLY6.txt',\n",
    "    '../owhm/model/2022/Data_Model_Arrays/layers/Initial_Head/WLCLY7.txt',\n",
    "    '../owhm/model/2022/Data_Model_Arrays/layers/Initial_Head/WLCLY8.txt',\n",
    "    '../owhm/model/2022/Data_Model_Arrays/layers/Initial_Head/WLCLY9.txt',\n",
    "]\n",
    "\n",
    "# read heads into 3d array, handle -999 as no data\n",
    "strt = np.zeros((nlay, nrow, ncol), dtype=float)\n",
    "for lay, head_file in enumerate(head_files):\n",
    "    try:\n",
    "        data = np.loadtxt(head_file, dtype=float)\n",
    "        if data.shape != (nrow, ncol):\n",
    "            print(f\"warning: {head_file} shape {data.shape} != ({nrow}, {ncol})\")\n",
    "            data = data.reshape(nrow, ncol)[:nrow, :ncol]\n",
    "        # handle -999 as NaN (not -99999)\n",
    "        data = np.where(data == -999, np.nan, data)  # replace -999 with NaN\n",
    "        strt[lay] = data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"error: {head_file} not found. IC requires this file. Exiting.\")\n",
    "        raise FileNotFoundError(f\"Error: {head_file} not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"error reading {head_file}: {e}. Exiting.\")\n",
    "        raise Exception(f\"Error reading {head_file}: {e}\")\n",
    "\n",
    "# fix strt for active cells (idomain == 1)\n",
    "mask_active = idomain == 1  # 3D mask for active cells\n",
    "for lay in range(nlay):\n",
    "    active_mask = mask_active[lay]\n",
    "    if np.isnan(strt[lay][active_mask]).any():\n",
    "        # interpolate or assign default heads for active cells\n",
    "        # use average of top and botm as default\n",
    "        default_head = (top[active_mask] + botm[lay][active_mask]) / 2\n",
    "        strt[lay][active_mask] = np.nan_to_num(strt[lay][active_mask], nan=default_head)\n",
    "        # clip to ensure strt is within [botm, top]\n",
    "        strt[lay][active_mask] = np.clip(strt[lay][active_mask], botm[lay][active_mask], top[active_mask])\n",
    "    # ensure no NaN or Inf remain\n",
    "    strt[lay] = np.nan_to_num(strt[lay], nan=np.nanmean(strt[lay][active_mask]), posinf=np.nanmean(strt[lay][active_mask]), neginf=np.nanmean(strt[lay][active_mask]))\n",
    "    strt[lay][~active_mask] = np.nan  # keep inactive cells as NaN\n",
    "\n",
    "# verify strt\n",
    "print(\"NaN in strt fixed after interpolation:\", np.isnan(strt).any())\n",
    "for lay in range(nlay):\n",
    "    strt_active = strt[lay][mask_active[lay]]\n",
    "    print(f\"Layer {lay} strt (active) min/max:\", strt_active.min() if len(strt_active) > 0 else \"No active cells\", strt_active.max() if len(strt_active) > 0 else \"No active cells\")\n",
    "\n",
    "# create ic package\n",
    "ic = flopy.mf6.ModflowGwfic(gwf, strt=strt)\n",
    "print(\"ic package created with -999 as no-data, idomain from shapefile, and interpolated active heads.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d4042e-7920-4e74-9b62-baab99aa7558",
   "metadata": {},
   "source": [
    "## wel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ab97b2d-9619-444f-acb2-291c8d86a5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 well files: ['MX_MnI_FEED.txt', 'NM_PDL_FEED.txt', 'NM_DOM_FEED.txt', 'NM_DOL_FEED.txt', 'NM_DCN_FEED.txt', 'NM_PDM_FEED.txt', 'TX_DOM_FEED.txt', 'NM_CLS_FEED.txt']\n",
      "File: MX_MnI_FEED.txt, Wells: 33, Unique Names: {'WEL_MNI_MX'}\n",
      "File: NM_PDL_FEED.txt, Wells: 73, Unique Names: {'WEL_DOM_NM'}\n",
      "File: NM_DOM_FEED.txt, Wells: 7182, Unique Names: {'WEL_DOM_NM'}\n",
      "File: NM_DOL_FEED.txt, Wells: 166, Unique Names: {'WEL_DOM_NM'}\n",
      "File: NM_DCN_FEED.txt, Wells: 3, Unique Names: {'WEL_DOM_NM'}\n",
      "File: NM_PDM_FEED.txt, Wells: 1308, Unique Names: {'WEL_DOM_NM'}\n",
      "File: TX_DOM_FEED.txt, Wells: 60, Unique Names: {'WEL_DOM_TX'}\n",
      "File: NM_CLS_FEED.txt, Wells: 85, Unique Names: {'WEL_DOM_NM'}\n",
      "Total Wells Read: 8910\n",
      "Total Flux Data Rows: 922\n",
      "First 5 Wells: [{'layer': 2, 'row': 751, 'column': 186, 'name': 'WEL_MNI_MX'}, {'layer': 2, 'row': 748, 'column': 186, 'name': 'WEL_MNI_MX'}, {'layer': 2, 'row': 755, 'column': 186, 'name': 'WEL_MNI_MX'}, {'layer': 2, 'row': 805, 'column': 155, 'name': 'WEL_MNI_MX'}, {'layer': 2, 'row': 825, 'column': 139, 'name': 'WEL_MNI_MX'}]\n",
      "Combined Unique Well Names: {'WEL_DOM_TX', 'WEL_MNI_MX', 'WEL_DOM_NM'}\n",
      "Stress Period 0 Data: [((0, 57, 150), -37.493399229, 'WEL_DOM_NM'), ((0, 60, 149), -37.493399229, 'WEL_DOM_NM'), ((0, 72, 148), -37.493399229, 'WEL_DOM_NM'), ((0, 78, 144), -37.493399229, 'WEL_DOM_NM'), ((0, 82, 135), -37.493399229, 'WEL_DOM_NM')]\n",
      "WEL package created successfully.\n"
     ]
    }
   ],
   "source": [
    "# wel package\n",
    "\n",
    "#dir\n",
    "well_folder = '../owhm/model/2022/Data_FeedFiles/WEL'\n",
    "\n",
    "#read well files\n",
    "well_files = [f for f in os.listdir(well_folder) if f.endswith('_FEED.txt')]\n",
    "print(f\"Found {len(well_files)} well files: {well_files}\")\n",
    "\n",
    "well_locations = []\n",
    "flux_data = []\n",
    "well_count = 0\n",
    "\n",
    "for well_file in well_files:\n",
    "    file_path = os.path.join(well_folder, well_file)\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    temp_locations = []\n",
    "    temp_flux = []\n",
    "    reading_locations = True\n",
    "\n",
    "    for line in lines:\n",
    "        if 'TEMPORAL INPUT' in line:\n",
    "            reading_locations = False\n",
    "            continue\n",
    "        if reading_locations:\n",
    "            if line.strip() and not line.startswith('#'):\n",
    "                parts = line.split()\n",
    "                layer = int(parts[0]) - 1\n",
    "                row = int(parts[1]) - 1\n",
    "                col = int(parts[2]) - 1\n",
    "                well_name = parts[3].strip()\n",
    "                temp_locations.append({'layer': layer, 'row': row, 'column': col, 'name': well_name})\n",
    "        else:\n",
    "            if line.strip() and not line.startswith('#'):\n",
    "                parts = line.split()\n",
    "                flux = []\n",
    "                for x in parts:\n",
    "                    if x.startswith('#'):\n",
    "                        break\n",
    "                    flux.append(float(x) if x.lower() != 'nan' else 0.0)\n",
    "                if flux:\n",
    "                    temp_flux.append(flux)\n",
    "\n",
    "    # debug well names per file\n",
    "    unique_names_in_file = set([loc['name'] for loc in temp_locations])\n",
    "    print(f\"File: {well_file}, Wells: {len(temp_locations)}, Unique Names: {unique_names_in_file}\")\n",
    "    \n",
    "    well_locations.extend(temp_locations)\n",
    "    if flux_data and len(temp_flux) > 0:\n",
    "        for i in range(len(flux_data)):\n",
    "            if i < len(temp_flux):\n",
    "                flux_data[i].extend(temp_flux[i])\n",
    "            else:\n",
    "                flux_data[i].extend([0.0] * len(temp_locations))  # pad with zeros\n",
    "        if len(flux_data) < len(temp_flux):\n",
    "            for i in range(len(flux_data), len(temp_flux)):\n",
    "                flux_data.append([0.0] * len(well_locations) + temp_flux[i])\n",
    "    else:\n",
    "        flux_data.extend(temp_flux)\n",
    "    \n",
    "    well_count += len(temp_locations)\n",
    "\n",
    "print(f\"Total Wells Read: {well_count}\")\n",
    "print(f\"Total Flux Data Rows: {len(flux_data)}\")\n",
    "print(f\"First 5 Wells: {well_locations[:5]}\")\n",
    "#print(f\"First 5 Rows of Flux Data: {flux_data[:5]}\")\n",
    "unique_well_names = set([well['name'] for well in well_locations])\n",
    "print(f\"Combined Unique Well Names: {unique_well_names}\")\n",
    "\n",
    "# prepare stress period data\n",
    "stress_period_data = {}\n",
    "previous_flux = None\n",
    "\n",
    "for sp in range(min(nper, len(flux_data))):\n",
    "    current_flux = flux_data[sp]\n",
    "    if sp == 0 or current_flux != previous_flux:\n",
    "        stress_period_data[sp] = []\n",
    "        for idx, well in enumerate(well_locations):\n",
    "            if idx < len(current_flux) and current_flux[idx] != 0.0:\n",
    "                well_tuple = ((well['layer'], well['row'], well['column']), current_flux[idx], well['name'])\n",
    "                stress_period_data[sp].append(well_tuple)\n",
    "       # print(f\"Added {len(stress_period_data[sp])} wells to Stress Period {sp}\")\n",
    "    previous_flux = current_flux\n",
    "\n",
    "if not stress_period_data:\n",
    "    raise ValueError(\"Error: stress_period_data is empty!\")\n",
    "else:\n",
    "    for sp in range(min(nper, 5)):\n",
    "        if sp in stress_period_data:\n",
    "            print(f\"Stress Period {sp} Data: {stress_period_data[sp][:5]}\") \n",
    "\n",
    "# create wel package\n",
    "wel = flopy.mf6.ModflowGwfwel(\n",
    "    gwf,\n",
    "    stress_period_data=stress_period_data,\n",
    "    save_flows=True,\n",
    "    boundnames=True,\n",
    "    print_input=True\n",
    ")\n",
    "print(\"WEL package created successfully.\")\n",
    "#max_wells = max(len(data) for data in stress_period_data.values() if data)\n",
    "#print(f\"Maximum wells in any stress period: {max_wells}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb3f102-befb-4923-a98f-47ed696d1b07",
   "metadata": {},
   "source": [
    "## npf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78361787-8d98-4670-b72b-6f10c33d50f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "npf package created from zonecode files and PVL/RGTIHM.PVL\n"
     ]
    }
   ],
   "source": [
    "## node property flow package for k and k33\n",
    "## in out case, horizontal and vertical conductivity - k11 and k22 is k, and k33 is conductivity of third ellipsoid axis - k33 tensor component. \n",
    "## turns out that k11 = k22 = k33 = k; since it is isotropic. we're using hk and vk.\n",
    "\n",
    "# npf package\n",
    "# zone file paths (relative to rgtihm-main/model)\n",
    "zone_files = {\n",
    "    'znlayrc': '../owhm/model/2022/Data_Model_Arrays/layers/El_IBD_Zone/RC1_zonecode.txt',\n",
    "    'znlay3': '../owhm/model/2022/Data_Model_Arrays/layers/El_IBD_Zone/USF1_zonecode.txt',\n",
    "    'znlay4': '../owhm/model/2022/Data_Model_Arrays/layers/El_IBD_Zone/USF2_zonecode.txt',\n",
    "    'znlay5': '../owhm/model/2022/Data_Model_Arrays/layers/El_IBD_Zone/MSF1_zonecode.txt',\n",
    "    'znlay6': '../owhm/model/2022/Data_Model_Arrays/layers/El_IBD_Zone/MSF2_zonecode.txt',\n",
    "    'znlay7': '../owhm/model/2022/Data_Model_Arrays/layers/El_IBD_Zone/LSF1_zonecode.txt',\n",
    "    'znlay8': '../owhm/model/2022/Data_Model_Arrays/layers/El_IBD_Zone/LSF2_zonecode.txt',\n",
    "    'znlay9': '../owhm/model/2022/Data_Model_Arrays/layers/El_IBD_Zone/BSMT_zonecodeS.txt',\n",
    "}\n",
    "\n",
    "# read zone arrays\n",
    "zone_arrays = {}\n",
    "for name, filepath in zone_files.items():\n",
    "    try:\n",
    "        data = np.loadtxt(filepath, dtype=int)\n",
    "        if data.shape != (nrow, ncol):\n",
    "            print(f\"warning: {filepath} shape {data.shape} != ({nrow}, {ncol})\")\n",
    "            data = data.reshape(nrow, ncol)[:nrow, :ncol]\n",
    "        zone_arrays[name] = data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"warning: {filepath} not found, using default zone 1.\")\n",
    "        zone_arrays[name] = np.ones((nrow, ncol), dtype=int)\n",
    "    except Exception as e:\n",
    "        print(f\"error reading {filepath}: {e}. using default zone 1.\")\n",
    "        zone_arrays[name] = np.ones((nrow, ncol), dtype=int)\n",
    "\n",
    "# layer-to-zone mapping\n",
    "layer_zones = {\n",
    "    0: 'znlayrc', 1: 'znlayrc', 2: 'znlay3', 3: 'znlay4',\n",
    "    4: 'znlay5', 5: 'znlay6', 6: 'znlay7', 7: 'znlay8', 8: 'znlay9'\n",
    "}\n",
    "\n",
    "# complete pval_data from RGTIHM.PVL for hydraulic conductivity\n",
    "pval_data = {\n",
    "    'l1hk10': 100.0, 'l1hk20': 30.0, 'l1hk30': 0.2629016, 'l1hk51': 0.14489073,\n",
    "    'l2hk10': 100.0, 'l2hk20': 30.0, 'l2hk30': 0.2629016, 'l2hk51': 0.14489073,\n",
    "    'l3hk15': 100.0, 'l3hk25': 100.0, 'l3hk35': 9.2195476, 'l3hk50': 30.0, 'l3hk51': 6.4479888,\n",
    "    'l3hk55': 1.0, 'l3hk60': 0.17476377, 'l3hk90': 0.01,\n",
    "    'l4hk15': 100.0, 'l4hk25': 100.0, 'l4hk35': 9.2195476, 'l4hk50': 30.0, 'l4hk51': 6.4479888,\n",
    "    'l4hk55': 1.0, 'l4hk60': 0.17476377, 'l4hk90': 0.01,\n",
    "    'l5hk35': 30.0, 'l5hk50': 0.20053775, 'l5hk55': 0.66872867, 'l5hk65': 1.0, 'l5hk90': 0.016224702,\n",
    "    'l5hk100': 0.035072631,\n",
    "    'l6hk25': 100.0, 'l6hk35': 30.0, 'l6hk40': 3.9352467, 'l6hk50': 0.20053775, 'l6hk55': 0.66872867,\n",
    "    'l6hk65': 1.0, 'l6hk90': 0.016224702, 'l6hk100': 0.035072631,\n",
    "    'l7hk35': 1.0, 'l7hk40': 2.1805362, 'l7hk55': 0.1, 'l7hk65': 0.38348569, 'l7hk90': 0.1, 'l7hk100': 0.023773051,\n",
    "    'l8hk35': 1.0, 'l8hk40': 2.1805362, 'l8hk55': 0.1, 'l8hk65': 0.38348569, 'l8hk90': 0.1, 'l8hk100': 0.023773051,\n",
    "    'l9hk11': 0.008606693, 'l9hk21': 0.58382645, 'l9hk31': 0.0042014914, 'l9hk41': 0.17529754, 'l9hk56': 10.0,\n",
    "    'l9hk61': 0.048328901, 'l9hk71': 3.2559841,\n",
    "    # vertical K (VK) for K33\n",
    "    'l1vk10': 1.091422, 'l1vk20': 1.2296545, 'l1vk30': 155.00641, 'l1vk51': 1003.4731,\n",
    "    'l2vk10': 1.091422, 'l2vk20': 1.2296545, 'l2vk30': 155.00641, 'l2vk51': 1003.4731,\n",
    "    'l3vk15': 1.0, 'l3vk25': 10.413017, 'l3vk35': 5.2372343, 'l3vk50': 6.9875221, 'l3vk51': 8.741806,\n",
    "    'l3vk55': 1358.6343, 'l3vk60': 1.0, 'l3vk90': 9.1188492,\n",
    "    'l4vk15': 1.0, 'l4vk25': 10.413017, 'l4vk35': 5.2372343, 'l4vk50': 6.9875221, 'l4vk51': 8.741806,\n",
    "    'l4vk55': 1358.6343, 'l4vk60': 1.0, 'l4vk90': 9.1188492,\n",
    "    'l5vk35': 1.0, 'l5vk50': 5845.6619, 'l5vk55': 11.489684, 'l5vk65': 17.306335, 'l5vk90': 112.8303,\n",
    "    'l5vk100': 10.288813,\n",
    "    'l6vk25': 4.4199196, 'l6vk35': 1.0, 'l6vk40': 247.36765, 'l6vk50': 5845.6619, 'l6vk55': 11.489684,\n",
    "    'l6vk65': 17.306335, 'l6vk90': 112.8303, 'l6vk100': 10.288813,\n",
    "    'l7vk35': 2.7818614, 'l7vk40': 2.3683035, 'l7vk55': 1.2711653, 'l7vk65': 11.44632, 'l7vk90': 1.0,\n",
    "    'l7vk100': 597.30784,\n",
    "    'l8vk35': 2.7818614, 'l8vk40': 2.3683035, 'l8vk55': 1.2711653, 'l8vk65': 11.44632, 'l8vk90': 1.0,\n",
    "    'l8vk100': 597.30784,\n",
    "    'l9vk11': 1.0, 'l9vk21': 48.550788, 'l9vk31': 2.7429583, 'l9vk41': 1.9085057, 'l9vk56': 29.289344,\n",
    "    'l9vk61': 1.0, 'l9vk71': 10000.0,\n",
    "    # K22 not explicitly in PVL, assume isotropic (k22 = hk)\n",
    "}\n",
    "\n",
    "# initialize arrays with no-data handling\n",
    "hk = np.ones((nlay, nrow, ncol), dtype=float) * 1e-10  # default K > 0\n",
    "k22 = hk.copy()  # y-direction K, defaults to hk (isotropic)\n",
    "k33 = hk.copy()  # vertical K, defaults to hk if no anisotropy\n",
    "icelltype = [0] * nlay  # confined by default, adjust if needed\n",
    "\n",
    "# populate hk, k22, k33, handle -99999 as no data\n",
    "for param, value in pval_data.items():\n",
    "    lay = int(param[1]) - 1\n",
    "    iz = int(param.split('hk' if 'hk' in param else 'vk')[1]) if 'hk' in param or 'vk' in param else 1\n",
    "    zone_array = zone_arrays[layer_zones[lay]]\n",
    "    mask = (zone_array == iz)\n",
    "    if value == -99999:  # treat -99999 as no data\n",
    "        hk[lay][mask] = np.nan\n",
    "        if 'vk' in param:\n",
    "            k33[lay][mask] = np.nan\n",
    "        else:\n",
    "            k22[lay][mask] = np.nan\n",
    "    else:\n",
    "        if 'hk' in param:\n",
    "            hk[lay][mask] = np.maximum(hk[lay][mask], value)  # ensure K > 0, use np.maximum for arrays\n",
    "            k22[lay][mask] = np.maximum(k22[lay][mask], value)  # assume isotropic unless K22 specified\n",
    "        elif 'vk' in param:\n",
    "            k33[lay][mask] = np.maximum(k33[lay][mask], value)  # vertical K\n",
    "            hk[lay][mask] = np.maximum(hk[lay][mask], 1e-10)  # ensure horizontal K > 0\n",
    "\n",
    "# update to match idomain (inactive cells from DIS)\n",
    "idomain = dis.idomain.array  # from dis package\n",
    "hk[idomain == 0] = np.nan  # set inactive cells to NaN\n",
    "k22[idomain == 0] = np.nan\n",
    "k33[idomain == 0] = np.nan\n",
    "\n",
    "# create npf with optional features\n",
    "npf = flopy.mf6.ModflowGwfnpf(\n",
    "    gwf,\n",
    "    save_flows=True,\n",
    "    icelltype=icelltype,\n",
    "    k=hk,\n",
    "    k22=k22,\n",
    "    k33=k33,\n",
    "    save_specific_discharge=True,\n",
    "    alternative_cell_averaging=\"harmonic\",  # match MF-OWHM’s likely averaging\n",
    "    # xt3d=True  # uncomment if 3D anisotropy is needed\n",
    ")\n",
    "print(\"npf package created from zonecode files and PVL/RGTIHM.PVL\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbc56a8-a2d6-42db-8cc6-2fb81926f505",
   "metadata": {},
   "source": [
    "## sto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa0333ba-cd73-42e2-a339-5d176ba5d8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sto package created\n"
     ]
    }
   ],
   "source": [
    "# sto package\n",
    "# multiplier and thickness file paths (relative to rgtihm-main/model)\n",
    "mult_files = {\n",
    "    'uc_rc': '../owhm/model/2022/Data_Model_Arrays/layers/CF_UC/RC1_UC.txt',\n",
    "    'uc_usf1': '../owhm/model/2022/Data_Model_Arrays/layers/CF_UC/USF1_UC.txt',\n",
    "    'cf_usf1': '../owhm/model/2022/Data_Model_Arrays/layers/CF_UC/USF1_CF.txt',\n",
    "    'uc_msf1': '../owhm/model/2022/Data_Model_Arrays/layers/CF_UC/MSF1_UC.txt',\n",
    "    'cf_msf1': '../owhm/model/2022/Data_Model_Arrays/layers/CF_UC/MSF1_CF.txt',\n",
    "    'uc_lsf1': '../owhm/model/2022/Data_Model_Arrays/layers/CF_UC/LSF1_UC.txt',\n",
    "    'cf_lsf1': '../owhm/model/2022/Data_Model_Arrays/layers/CF_UC/LSF1_CF.txt',\n",
    "    'uc_bd': '../owhm/model/2022/Data_Model_Arrays/layers/CF_UC/BSMT_UC.txt',\n",
    "    'cf_bd': '../owhm/model/2022/Data_Model_Arrays/layers/CF_UC/BSMT_CF.txt',\n",
    "    'thk_rc1': '../owhm/model/2022/Data_Model_Arrays/layers/Geometry/THK_RC1_ft.txt',\n",
    "    'thk_usf1': '../owhm/model/2022/Data_Model_Arrays/layers/Geometry/THK_USF1_ft.txt',\n",
    "    'thk_msf1': '../owhm/model/2022/Data_Model_Arrays/layers/Geometry/THK_MSF1_ft.txt',\n",
    "    'thk_lsf1': '../owhm/model/2022/Data_Model_Arrays/layers/Geometry/THK_LSF1_ft.txt',\n",
    "    'thk_bd': '../owhm/model/2022/Data_Model_Arrays/layers/Geometry/THK_BSMT_ft.txt',\n",
    "}\n",
    "\n",
    "# read multiplier and thickness arrays, handle -99999 as no data\n",
    "mult_arrays = {}\n",
    "for name, filepath in mult_files.items():\n",
    "    try:\n",
    "        data = np.loadtxt(filepath, dtype=float)\n",
    "        if data.shape != (nrow, ncol):\n",
    "            print(f\"warning: {filepath} shape {data.shape} != ({nrow}, {ncol})\")\n",
    "            data = data.reshape(nrow, ncol)[:nrow, :ncol]\n",
    "        data = np.where(data == -99999, np.nan, data * 0.3048 if 'thk' in name else data)  # convert thk ft to m\n",
    "        mult_arrays[name] = data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"warning: {filepath} not found, using default 1.0.\")\n",
    "        mult_arrays[name] = np.ones((nrow, ncol), dtype=float)\n",
    "    except Exception as e:\n",
    "        print(f\"error reading {filepath}: {e}. using default 1.0.\")\n",
    "        mult_arrays[name] = np.ones((nrow, ncol), dtype=float)\n",
    "\n",
    "# constants from mul\n",
    "ss_base = 0.000001  # default specific storage (1/m)\n",
    "sy_base = 0.30  # default specific yield\n",
    "phi = {'rc': 0.25, 'us': 0.22, 'ms': 0.12, 'ls': 0.08, 'bd': 0.07}  # porosity by layer group\n",
    "comp_h2o = 1.432195e-06  # water compressibility (1/m)\n",
    "offset = 0.0001  # small offset for thickness to avoid division by zero\n",
    "\n",
    "# zone file paths (relative to rgtihm-main/model, from npf)\n",
    "zone_files = {\n",
    "    'znlayrc': '../owhm/model/2022/Data_Model_Arrays/layers/El_IBD_Zone/RC1_zonecode.txt',\n",
    "    'znlay3': '../owhm/model/2022/Data_Model_Arrays/layers/El_IBD_Zone/USF1_zonecode.txt',\n",
    "    'znlay4': '../owhm/model/2022/Data_Model_Arrays/layers/El_IBD_Zone/USF2_zonecode.txt',\n",
    "    'znlay5': '../owhm/model/2022/Data_Model_Arrays/layers/El_IBD_Zone/MSF1_zonecode.txt',\n",
    "    'znlay6': '../owhm/model/2022/Data_Model_Arrays/layers/El_IBD_Zone/MSF2_zonecode.txt',\n",
    "    'znlay7': '../owhm/model/2022/Data_Model_Arrays/layers/El_IBD_Zone/LSF1_zonecode.txt',\n",
    "    'znlay8': '../owhm/model/2022/Data_Model_Arrays/layers/El_IBD_Zone/LSF2_zonecode.txt',\n",
    "    'znlay9': '../owhm/model/2022/Data_Model_Arrays/layers/El_IBD_Zone/BSMT_zonecodeS.txt',\n",
    "}\n",
    "\n",
    "# read zone arrays (reuse from npf if already loaded, or load here)\n",
    "zone_arrays = {}\n",
    "for name, filepath in zone_files.items():\n",
    "    if name not in zone_arrays:  # avoid reloading if npf already loaded\n",
    "        try:\n",
    "            data = np.loadtxt(filepath, dtype=int)\n",
    "            if data.shape != (nrow, ncol):\n",
    "                print(f\"warning: {filepath} shape {data.shape} != ({nrow}, {ncol})\")\n",
    "                data = data.reshape(nrow, ncol)[:nrow, :ncol]\n",
    "            zone_arrays[name] = data\n",
    "        except FileNotFoundError:\n",
    "            print(f\"warning: {filepath} not found, using default zone 1.\")\n",
    "            zone_arrays[name] = np.ones((nrow, ncol), dtype=int)\n",
    "        except Exception as e:\n",
    "            print(f\"error reading {filepath}: {e}. using default zone 1.\")\n",
    "            zone_arrays[name] = np.ones((nrow, ncol), dtype=int)\n",
    "\n",
    "# layer-to-zone mapping (from npf)\n",
    "layer_zones = {\n",
    "    0: 'znlayrc', 1: 'znlayrc', 2: 'znlay3', 3: 'znlay4',\n",
    "    4: 'znlay5', 5: 'znlay6', 6: 'znlay7', 7: 'znlay8', 8: 'znlay9'\n",
    "}\n",
    "\n",
    "# complete pval_data from RGTIHM.PVL for storage\n",
    "pval_data = {\n",
    "    'l2ss10': 5.0, 'l2ss20': 25.0, 'l2ss30': 8.2691995, 'l2ss51': 8.758604,\n",
    "    'l3ss15': 1.0955468, 'l3ss25': 2.9409115, 'l3ss35': 3.33, 'l3ss50': 1.069701, 'l3ss51': 2.0, 'l3ss55': 10.0,\n",
    "    'l3ss60': 5.1091253, 'l3ss90': 6.5520935,\n",
    "    'l4ss15': 1.0955468, 'l4ss25': 2.9409115, 'l4ss35': 3.33, 'l4ss50': 1.069701, 'l4ss51': 2.0, 'l4ss55': 10.0,\n",
    "    'l4ss60': 5.1091253, 'l4ss90': 6.5520935,\n",
    "    'l5ss35': 0.4, 'l5ss50': 0.80498139, 'l5ss55': 1.104017, 'l5ss65': 0.5723319, 'l5ss90': 0.71704178,\n",
    "    'l5ss100': 1.67,\n",
    "    'l6ss25': 1.67, 'l6ss35': 0.4, 'l6ss40': 0.95152044, 'l6ss50': 0.80498139, 'l6ss55': 1.104017, 'l6ss65': 0.5723319,\n",
    "    'l6ss90': 0.71704178, 'l6ss100': 1.67,\n",
    "    'l7ss35': 1.2993514, 'l7ss40': 2.33, 'l7ss55': 2.33, 'l7ss65': 2.050916, 'l7ss90': 0.91998654, 'l7ss100': 1.4320346,\n",
    "    'l8ss35': 1.2993514, 'l8ss40': 2.33, 'l8ss55': 2.33, 'l8ss65': 2.050916, 'l8ss90': 0.91998654, 'l8ss100': 1.4320346,\n",
    "    'l9ss11': 2.33, 'l9ss21': 2.33, 'l9ss31': 0.88759879, 'l9ss41': 0.91689225, 'l9ss56': 0.667, 'l9ss61': 1.8936826,\n",
    "    'l9ss71': 2.33,\n",
    "    'l1sy10': 1.0, 'l1sy20': 1.0, 'l1sy30': 0.825, 'l1sy51': 1.0,\n",
    "    'l3sy15': 0.50864162, 'l3sy25': 0.87375378, 'l3sy35': 0.59566227, 'l3sy50': 0.553, 'l3sy51': 0.29098953,\n",
    "    'l3sy55': 0.73273826, 'l3sy60': 0.37109912, 'l3sy90': 0.2,\n",
    "    'l5sy35': 0.536, 'l5sy50': 0.83810284, 'l5sy55': 1.0, 'l5sy65': 1.0, 'l5sy90': 0.51269604, 'l5sy100': 0.333,\n",
    "    'l7sy35': 0.59566227, 'l7sy40': 0.88904665, 'l7sy55': 0.64751193, 'l7sy65': 0.83651446, 'l7sy90': 0.44452383,\n",
    "    'l7sy100': 0.44452383,\n",
    "    'l9sy11': 0.74220455, 'l9sy21': 0.333, 'l9sy31': 0.89490974, 'l9sy41': 0.87571372, 'l9sy56': 0.39531322,\n",
    "    'l9sy61': 1.0, 'l9sy71': 1.0,\n",
    "}\n",
    "\n",
    "# initialize arrays with no-data handling\n",
    "ss = np.ones((nlay, nrow, ncol), dtype=float) * ss_base  # default specific storage (1/m)\n",
    "sy = np.ones((nlay, nrow, ncol), dtype=float) * sy_base  # default specific yield\n",
    "iconvert = [0] * nlay  # confined by default, adjust if needed\n",
    "\n",
    "# populate ss and sy with PVL values, handle -99999 and multipliers\n",
    "for param, value in pval_data.items():\n",
    "    lay = int(param[1]) - 1\n",
    "    iz = int(param.split('ss' if 'ss' in param else 'sy')[1]) if 'ss' in param or 'sy' in param else 1\n",
    "    zone_array = zone_arrays[layer_zones[lay]]\n",
    "    mask = (zone_array == iz)\n",
    "    if value == -99999:  # treat -99999 as no data\n",
    "        ss[lay][mask] = np.nan\n",
    "        sy[lay][mask] = np.nan\n",
    "    else:\n",
    "        if 'ss' in param:\n",
    "            ss[lay][mask] = np.maximum(ss[lay][mask], value)  # ensure SS > 0, use np.maximum\n",
    "        elif 'sy' in param:\n",
    "            sy[lay][mask] = np.clip(value, 0.0, 1.0)  # ensure 0 < SY < 1\n",
    "\n",
    "# apply multipliers and thickness, handle NaN\n",
    "for lay in range(nlay):\n",
    "    zone_array = zone_arrays[layer_zones[lay]]\n",
    "    if lay in [0, 1]:  # rc\n",
    "        thk = mult_arrays['thk_rc1']\n",
    "        uc = mult_arrays['uc_rc']\n",
    "        ss[lay] = np.where(np.isnan(ss[lay]) | np.isnan(uc) | np.isnan(thk), np.nan,\n",
    "                           np.maximum(ss[lay], (phi['rc'] * comp_h2o + ss_base) * uc))\n",
    "        sy[lay] = np.where(np.isnan(sy[lay]) | np.isnan(uc) | np.isnan(thk), np.nan,\n",
    "                           np.clip((sy_base / (thk + offset) + phi['rc'] * comp_h2o) * uc, 0.0, 1.0))\n",
    "    elif lay in [2, 3]:  # usf\n",
    "        thk = mult_arrays['thk_usf1']\n",
    "        uc = mult_arrays['uc_usf1']\n",
    "        cf = mult_arrays['cf_usf1']\n",
    "        ss[lay] = np.where(np.isnan(ss[lay]) | np.isnan(uc) | np.isnan(cf) | np.isnan(thk), np.nan,\n",
    "                           np.maximum(ss[lay], (phi['us'] * comp_h2o + ss_base) * (cf + uc) if lay == 3 else (phi['us'] * comp_h2o) * cf + ss_base * cf))\n",
    "        sy[lay] = np.where(np.isnan(sy[lay]) | np.isnan(uc) | np.isnan(cf) | np.isnan(thk), np.nan,\n",
    "                           np.clip((sy_base / (thk + offset) + phi['us'] * comp_h2o) * uc, 0.0, 1.0))\n",
    "    elif lay in [4, 5]:  # msf\n",
    "        thk = mult_arrays['thk_msf1']\n",
    "        uc = mult_arrays['uc_msf1']\n",
    "        cf = mult_arrays['cf_msf1']\n",
    "        ss[lay] = np.where(np.isnan(ss[lay]) | np.isnan(uc) | np.isnan(cf) | np.isnan(thk), np.nan,\n",
    "                           np.maximum(ss[lay], (phi['ms'] * comp_h2o + ss_base) * (cf + uc) if lay == 5 else (phi['ms'] * comp_h2o) * cf + ss_base * cf))\n",
    "        sy[lay] = np.where(np.isnan(sy[lay]) | np.isnan(uc) | np.isnan(cf) | np.isnan(thk), np.nan,\n",
    "                           np.clip((sy_base / (thk + offset) + phi['ms'] * comp_h2o) * uc, 0.0, 1.0))\n",
    "    elif lay in [6, 7]:  # lsf\n",
    "        thk = mult_arrays['thk_lsf1']\n",
    "        uc = mult_arrays['uc_lsf1']\n",
    "        cf = mult_arrays['cf_lsf1']\n",
    "        ss[lay] = np.where(np.isnan(ss[lay]) | np.isnan(uc) | np.isnan(cf) | np.isnan(thk), np.nan,\n",
    "                           np.maximum(ss[lay], (phi['ls'] * comp_h2o + ss_base) * (cf + uc) if lay == 7 else (phi['ls'] * comp_h2o) * cf + ss_base * cf))\n",
    "        sy[lay] = np.where(np.isnan(sy[lay]) | np.isnan(uc) | np.isnan(cf) | np.isnan(thk), np.nan,\n",
    "                           np.clip((sy_base / (thk + offset) + phi['ls'] * comp_h2o) * uc, 0.0, 1.0))\n",
    "    elif lay == 8:  # bd\n",
    "        thk = mult_arrays['thk_bd']\n",
    "        uc = mult_arrays['uc_bd']\n",
    "        cf = mult_arrays['cf_bd']\n",
    "        ss[lay] = np.where(np.isnan(ss[lay]) | np.isnan(uc) | np.isnan(cf) | np.isnan(thk), np.nan,\n",
    "                           np.maximum(ss[lay], (phi['bd'] * comp_h2o + ss_base) * (cf + uc)))\n",
    "        sy[lay] = np.where(np.isnan(sy[lay]) | np.isnan(uc) | np.isnan(cf) | np.isnan(thk), np.nan,\n",
    "                           np.clip((sy_base / (thk + offset) + phi['bd'] * comp_h2o) * uc, 0.0, 1.0))\n",
    "\n",
    "# update ss and sy to match idomain (inactive cells from DIS)\n",
    "idomain = dis.idomain.array  # from dis package\n",
    "ss[idomain == 0] = np.nan  # set inactive cells to NaN\n",
    "sy[idomain == 0] = np.nan\n",
    "\n",
    "# create sto\n",
    "sto = flopy.mf6.ModflowGwfsto(\n",
    "    gwf,\n",
    "    save_flows=True,\n",
    "    iconvert=iconvert,\n",
    "    ss=ss,\n",
    "    sy=sy,\n",
    "    transient=True,\n",
    ")\n",
    "print(\"sto package created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fba66418-9463-409c-929e-2b5f942f08ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hfb, wel, maw, sfr, ghb, et, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "361acdae-0990-44a4-88e1-79d21200356a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN in hk fixed: False\n",
      "Layer 0 hk (active) min/max: 1e-10 100.0\n",
      "Layer 1 hk (active) min/max: 1e-10 100.0\n",
      "Layer 2 hk (active) min/max: 1e-10 100.0\n",
      "Layer 3 hk (active) min/max: 1e-10 100.0\n",
      "Layer 4 hk (active) min/max: 1e-10 30.0\n",
      "Layer 5 hk (active) min/max: 1e-10 100.0\n",
      "Layer 6 hk (active) min/max: 1e-10 2.1805362\n",
      "Layer 7 hk (active) min/max: 1e-10 2.1805362\n",
      "Layer 8 hk (active) min/max: 0.0042014914 10.0\n",
      "NaN in ss fixed: False\n",
      "Layer 0 ss (active) min/max: 1e-06 1.35804875e-06\n",
      "Layer 0 sy (active) min/max: 0.0 0.019685268252751284\n",
      "Layer 1 ss (active) min/max: 1e-06 25.0\n",
      "Layer 1 sy (active) min/max: 0.0 0.019685268252751284\n",
      "Layer 2 ss (active) min/max: 1e-06 10.0\n",
      "Layer 2 sy (active) min/max: 0.0 0.4920455832475711\n",
      "Layer 3 ss (active) min/max: 1e-06 10.0\n",
      "Layer 3 sy (active) min/max: 0.0 0.4920455832475711\n",
      "Layer 4 ss (active) min/max: 1e-06 1.104017\n",
      "Layer 4 sy (active) min/max: 0.0 0.0\n",
      "Layer 5 ss (active) min/max: 1e-06 1.67\n",
      "Layer 5 sy (active) min/max: 0.0 0.0\n",
      "Layer 6 ss (active) min/max: 1e-06 2.33\n",
      "Layer 6 sy (active) min/max: 0.0 0.0\n",
      "Layer 7 ss (active) min/max: 1e-06 2.33\n",
      "Layer 7 sy (active) min/max: 0.0 0.0\n",
      "Layer 8 ss (active) min/max: 0.667 2.33\n",
      "Layer 8 sy (active) min/max: 0.0 0.0019686028989894717\n",
      "NaN in strt fixed: True\n",
      "Layer 0 strt (active) min/max: nan nan\n",
      "Layer 1 strt (active) min/max: nan nan\n",
      "Layer 2 strt (active) min/max: nan nan\n",
      "Layer 3 strt (active) min/max: nan nan\n",
      "Layer 4 strt (active) min/max: nan nan\n",
      "Layer 5 strt (active) min/max: nan nan\n",
      "Layer 6 strt (active) min/max: nan nan\n",
      "Layer 7 strt (active) min/max: nan nan\n",
      "Layer 8 strt (active) min/max: nan nan\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MFPandasTransientList' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m strt (active) min/max:\u001b[39m\u001b[38;5;124m\"\u001b[39m, strt_active\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(strt_active) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo active cells\u001b[39m\u001b[38;5;124m\"\u001b[39m, strt_active\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(strt_active) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo active cells\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# check WEL fluxes (already verified in your output, but add for completeness)\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m fluxes \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m sp_data \u001b[38;5;129;01min\u001b[39;00m \u001b[43mwel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstress_period_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m() \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m sp_data \u001b[38;5;28;01mif\u001b[39;00m sp_data]\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWEL fluxes min/max:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mmin\u001b[39m(fluxes) \u001b[38;5;28;01mif\u001b[39;00m fluxes \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fluxes\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mmax\u001b[39m(fluxes) \u001b[38;5;28;01mif\u001b[39;00m fluxes \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fluxes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN in WEL fluxes:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28many\u001b[39m(np\u001b[38;5;241m.\u001b[39misnan(fluxes)) \u001b[38;5;28;01mif\u001b[39;00m fluxes \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MFPandasTransientList' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "# create 3D mask for active cells (idomain == 1) across all layers\n",
    "mask_active = idomain == 1  # shape (nlay, nrow, ncol)\n",
    "\n",
    "# check and fix NaN/invalid values in NPF\n",
    "hk = np.nan_to_num(hk, nan=1e-10, posinf=1e-10, neginf=1e-10)  # ensure K > 0\n",
    "k22 = np.nan_to_num(k22, nan=1e-10, posinf=1e-10, neginf=1e-10)\n",
    "k33 = np.nan_to_num(k33, nan=1e-10, posinf=1e-10, neginf=1e-10)\n",
    "print(\"NaN in hk fixed:\", np.isnan(hk).any())\n",
    "for lay in range(nlay):\n",
    "    hk_active = hk[lay][mask_active[lay]]  # apply mask per layer\n",
    "    print(f\"Layer {lay} hk (active) min/max:\", hk_active.min() if len(hk_active) > 0 else \"No active cells\", hk_active.max() if len(hk_active) > 0 else \"No active cells\")\n",
    "\n",
    "# check and fix NaN/invalid values in STO\n",
    "ss = np.nan_to_num(ss, nan=ss_base, posinf=ss_base, neginf=ss_base)  # ensure SS > 0\n",
    "sy = np.nan_to_num(sy, nan=sy_base, posinf=sy_base, neginf=sy_base)  # ensure 0 < SY < 1\n",
    "sy = np.clip(sy, 0.0, 1.0)\n",
    "print(\"NaN in ss fixed:\", np.isnan(ss).any())\n",
    "for lay in range(nlay):\n",
    "    ss_active = ss[lay][mask_active[lay]]\n",
    "    sy_active = sy[lay][mask_active[lay]]\n",
    "    print(f\"Layer {lay} ss (active) min/max:\", ss_active.min() if len(ss_active) > 0 else \"No active cells\", ss_active.max() if len(ss_active) > 0 else \"No active cells\")\n",
    "    print(f\"Layer {lay} sy (active) min/max:\", sy_active.min() if len(sy_active) > 0 else \"No active cells\", sy_active.max() if len(sy_active) > 0 else \"No active cells\")\n",
    "\n",
    "# check and fix NaN/invalid values in IC\n",
    "strt = np.nan_to_num(strt, nan=np.nanmean(strt[mask_active]), posinf=np.nanmean(strt[mask_active]), neginf=np.nanmean(strt[mask_active]))\n",
    "for lay in range(nlay):\n",
    "    mask_active_lay = mask_active[lay]\n",
    "    strt[lay][~mask_active_lay] = np.nan  # keep inactive as NaN\n",
    "    strt[lay][mask_active_lay] = np.clip(strt[lay][mask_active_lay], botm[lay][mask_active_lay], top[mask_active_lay])\n",
    "print(\"NaN in strt fixed:\", np.isnan(strt).any())\n",
    "for lay in range(nlay):\n",
    "    strt_active = strt[lay][mask_active[lay]]\n",
    "    print(f\"Layer {lay} strt (active) min/max:\", strt_active.min() if len(strt_active) > 0 else \"No active cells\", strt_active.max() if len(strt_active) > 0 else \"No active cells\")\n",
    "\n",
    "# check WEL fluxes (already verified in your output, but add for completeness)\n",
    "fluxes = [item[1] for sp_data in wel.stress_period_data.values() for item in sp_data if sp_data]\n",
    "print(\"WEL fluxes min/max:\", min(fluxes) if fluxes else \"No fluxes\", max(fluxes) if fluxes else \"No fluxes\")\n",
    "print(\"NaN in WEL fluxes:\", any(np.isnan(fluxes)) if fluxes else False)\n",
    "\n",
    "# update packages if needed (e.g., NPF, STO, IC)\n",
    "npf.k = hk\n",
    "npf.k22 = k22\n",
    "npf.k33 = k33\n",
    "sto.ss = ss\n",
    "sto.sy = sy\n",
    "ic.strt = strt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275edc73-0325-4ab7-a4b8-bd09cf2bd847",
   "metadata": {},
   "source": [
    "## write and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a71f9df-2178-4146-a222-8c4decc7d71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing simulation...\n",
      "  writing simulation name file...\n",
      "  writing simulation tdis package...\n",
      "  writing solution package ims...\n",
      "  writing model rgtihm...\n",
      "    writing model name file...\n",
      "    writing package dis...\n",
      "    writing package oc...\n",
      "    writing package wel_0...\n",
      "    writing package npf...\n",
      "    writing package sto...\n",
      "    writing package ic...\n",
      "simulation written to ./model directory. Check for errors.\n"
     ]
    }
   ],
   "source": [
    "# write simulation\n",
    "sim.write_simulation()\n",
    "\n",
    "# optionally run simulation (uncomment to test)\n",
    "# sim.run_simulation()\n",
    "\n",
    "print(\"simulation written to ./model directory. Check for errors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c385467c-68be-4977-871b-ea22dc502c70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a851fd25-9705-47f1-9d94-f062e0a76b75",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bce538-0359-4fa0-ac7d-c272329a9e02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09409c93-b863-4f65-92da-c0bbf19c7168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid coords in meters (from dis)\n",
    "xll = dis.xorigin.get_data()\n",
    "yll = dis.yorigin.get_data()\n",
    "angrot = dis.angrot.get_data()\n",
    "delr = dis.delr.get_data()\n",
    "delc = dis.delc.get_data()\n",
    "x = np.arange(ncol) * delr[0]\n",
    "y = np.arange(nrow) * delc[0]\n",
    "X, Y = np.meshgrid(x, y)\n",
    "X_rot = xll + X * np.cos(np.radians(angrot)) - Y * np.sin(np.radians(angrot))\n",
    "Y_rot = yll + X * np.sin(np.radians(angrot)) + Y * np.cos(np.radians(angrot))\n",
    "\n",
    "# 1. overall model domain with idomain and shapefile\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(idomain[0], extent=[X_rot.min(), X_rot.max(), Y_rot.min(), Y_rot.max()], cmap='binary', alpha=0.5)\n",
    "gdf.plot(ax=ax, edgecolor='red', facecolor='none', linewidth=2)\n",
    "cx.add_basemap(ax, crs=model_crs, source=cx.providers.OpenStreetMap.Mapnik)\n",
    "ax.set_title('model domain with idomain (layer 1) and active_area.shp')\n",
    "ax.set_xlabel('easting (m)')\n",
    "ax.set_ylabel('northing (m)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. grid outline with idomain\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "cmap = plt.cm.colors.ListedColormap(['white', 'lightgrey'])\n",
    "bounds = [0, 1, 2]\n",
    "norm = plt.cm.colors.BoundaryNorm(bounds, cmap.N)\n",
    "ax.imshow(idomain[0], extent=[X_rot.min(), X_rot.max(), Y_rot.min(), Y_rot.max()], cmap=cmap, norm=norm, alpha=0.8, interpolation='nearest')\n",
    "gdf.plot(ax=ax, edgecolor='lightgrey', facecolor='none', linewidth=2, alpha=0.5)\n",
    "for i in range(nrow):\n",
    "    ax.plot([X_rot[i, 0], X_rot[i, -1]], [Y_rot[i, 0], Y_rot[i, -1]], 'k-', lw=0.5)\n",
    "for j in range(ncol):\n",
    "    ax.plot([X_rot[0, j], X_rot[-1, j]], [Y_rot[0, j], Y_rot[-1, j]], 'k-', lw=0.5)\n",
    "cx.add_basemap(ax, crs=model_crs, source=cx.providers.OpenStreetMap.Mapnik)\n",
    "ax.set_title('grid with idomain (layer 1)')\n",
    "ax.set_xlabel('easting (m)')\n",
    "ax.set_ylabel('northing (m)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e81020e-d5e1-496e-ba3f-0f2143331c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-sections for rows 538, 741, 103, and column 75\n",
    "rows = [538, 741, 103]\n",
    "col = 75\n",
    "\n",
    "# Corrected geological layer names (only 9 layers, not 10)\n",
    "layer_names = [\"Top RC1\", \"Top RC2\", \"Top USF1\", \"Top USF2\", \n",
    "               \"Top MSF1\", \"Top MSF2\", \"Top LSF1\", \"Top LSF2\", \n",
    "               \"Top BSMT\"]  # Removed \"Base BSMT\" since it's botm[-1]\n",
    "\n",
    "for row in rows:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6), gridspec_kw={'width_ratios': [3, 1]})\n",
    "\n",
    "    # elevation profile - now plotting geological layers for all cells, ignoring idomain\n",
    "    for lay, name in zip(range(nlay), layer_names):\n",
    "        bot = botm[lay, row, :]\n",
    "        ax1.plot(X_rot[row, :], bot, label=name)\n",
    "\n",
    "    ax1.plot(X_rot[row, :], top[row, :], 'k-', label='Elev')\n",
    "\n",
    "    # Check and print inactive cells per layer\n",
    "    inactive_cells = [(name, (idomain[lay, row, :] == 0).sum()) for lay, name in enumerate(layer_names)]\n",
    "    print(f\"Inactive cells in row {row}: {inactive_cells}\")\n",
    "\n",
    "    # Previously shaded active cells, now showing full geological layers\n",
    "    ax1.fill_between(X_rot[row, :], botm[-1, row, :], top[row, :], color='gray', alpha=0.3)\n",
    "\n",
    "    ax1.set_title(f'cross-section (row {row})')\n",
    "    ax1.set_xlabel('easting (m)')\n",
    "    ax1.set_ylabel('elevation (m)')\n",
    "    ax1.legend()\n",
    "\n",
    "    # basemap inset for location\n",
    "    ax2.imshow(idomain[0], extent=[X_rot.min(), X_rot.max(), Y_rot.min(), Y_rot.max()], cmap='binary', alpha=0.5)\n",
    "    gdf.plot(ax=ax2, edgecolor='red', facecolor='none', linewidth=2)\n",
    "    cx.add_basemap(ax2, crs=model_crs, source=cx.providers.OpenStreetMap.Mapnik)\n",
    "    ax2.plot(X_rot[row, :], Y_rot[row, :], 'b-', lw=2, label='cross-section line')\n",
    "    ax2.set_title('location map')\n",
    "    ax2.legend()\n",
    "    ax2.set_xticks([])\n",
    "    ax2.set_yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# cross-section for column 75\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6), gridspec_kw={'width_ratios': [3, 1]})\n",
    "\n",
    "for lay, name in zip(range(nlay), layer_names):\n",
    "    bot = botm[lay, :, col]\n",
    "    ax1.plot(Y_rot[:, col], bot, label=name)\n",
    "\n",
    "ax1.plot(Y_rot[:, col], top[:, col], 'k-', label='Elev')\n",
    "\n",
    "# Check and print inactive cells in the column\n",
    "inactive_cells_col = [(name, (idomain[lay, :, col] == 0).sum()) for lay, name in enumerate(layer_names)]\n",
    "print(f\"Inactive cells in column {col}: {inactive_cells_col}\")\n",
    "\n",
    "ax1.fill_between(Y_rot[:, col], botm[-1, :, col], top[:, col], color='gray', alpha=0.3)\n",
    "ax1.set_title(f'cross-section (column {col})')\n",
    "ax1.set_xlabel('northing (m)')\n",
    "ax1.set_ylabel('elevation (m)')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.imshow(idomain[0], extent=[X_rot.min(), X_rot.max(), Y_rot.min(), Y_rot.max()], cmap='binary', alpha=0.5)\n",
    "gdf.plot(ax=ax2, edgecolor='red', facecolor='none', linewidth=2)\n",
    "cx.add_basemap(ax2, crs=model_crs, source=cx.providers.OpenStreetMap.Mapnik)\n",
    "ax2.plot(X_rot[:, col], Y_rot[:, col], 'b-', lw=2, label='cross-section line')\n",
    "ax2.set_title('location map')\n",
    "ax2.legend()\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9dac44-b689-4822-81d2-72672246ddea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0d7ffd-1e51-49d7-bdc2-6cd27bb076b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
